# src/realtime_detect.py
# -----------------------------------------------------
# Ph√°t hi·ªán m≈© b·∫£o hi·ªÉm theo th·ªùi gian th·ª±c v√† l∆∞u video
# -----------------------------------------------------

from ultralytics import YOLO
import cv2
import time
import os

# 1. N·∫°p m√¥ h√¨nh
model = YOLO("models/best.pt")

# 2. M·ªü webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam. Th·ª≠ cap = cv2.VideoCapture(1)")
    exit()

print("‚úÖ Webcam ƒë√£ m·ªü th√†nh c√¥ng.")
print("üöÄ Nh·∫•n 'q' ƒë·ªÉ d·ª´ng quay v√† l∆∞u video...")

# 3. T·∫°o th∆∞ m·ª•c l∆∞u video
save_dir = "runs/realtime_video"
os.makedirs(save_dir, exist_ok=True)

# 4. Chu·∫©n b·ªã file video output
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
timestamp = time.strftime("%Y%m%d-%H%M%S")
output_path = os.path.join(save_dir, f"helmet_realtime_{timestamp}.mp4")

# L·∫•y k√≠ch th∆∞·ªõc khung h√¨nh t·ª´ webcam
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame_width, frame_height))

# 5. Ch·∫°y ph√°t hi·ªán v√† ghi video
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # D·ª± ƒëo√°n
    results = model(frame, conf=0.25)
    annotated_frame = results[0].plot()

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ l√™n m√†n h√¨nh
    cv2.imshow("Helmet Detection - Realtime", annotated_frame)

    # Ghi frame c√≥ bounding box v√†o video
    out.write(annotated_frame)

    # Nh·∫•n 'q' ƒë·ªÉ d·ª´ng
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 6. Gi·∫£i ph√≥ng t√†i nguy√™n
cap.release()
out.release()
cv2.destroyAllWindows()

print(f"‚úÖ Video ƒë√£ l∆∞u t·∫°i: {output_path}")
